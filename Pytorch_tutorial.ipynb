{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import Relevant Packages\n"
      ],
      "metadata": {
        "id": "lcRiszWN_CwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2652XooZMcPF",
        "outputId": "6c70f9c0-c3bb-44eb-874e-1fa7430d10c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "8haNxZeL_G4u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Linear Regression from scratch"
      ],
      "metadata": {
        "id": "uN_JP8TsG786"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oucmgbEfpHcw",
        "outputId": "7b5323a2-29be-4a00-d9b2-a1c169ec1cb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 1.200, loss = 30.00000000\n",
            "epoch 2: w = 1.680, loss = 4.79999924\n",
            "epoch 3: w = 1.872, loss = 0.76800019\n",
            "epoch 4: w = 1.949, loss = 0.12288000\n",
            "epoch 5: w = 1.980, loss = 0.01966083\n",
            "epoch 6: w = 1.992, loss = 0.00314574\n",
            "epoch 7: w = 1.997, loss = 0.00050331\n",
            "epoch 8: w = 1.999, loss = 0.00008053\n",
            "epoch 9: w = 1.999, loss = 0.00001288\n",
            "epoch 10: w = 2.000, loss = 0.00000206\n",
            "Prediction after training: f(5) = 9.999\n"
          ]
        }
      ],
      "source": [
        "# f = w*x\n",
        "# f = 2*x\n",
        "\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "# loss\n",
        "def loss(y, y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "# gradient\n",
        "def gradient(x, y, y_predicted):\n",
        "  return np.dot(2*x, y_predicted-y).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradient\n",
        "  dw = gradient(X, Y, y_pred)\n",
        "\n",
        "  # update weights\n",
        "  w -= learning_rate * dw\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression (gradient with pytorch)"
      ],
      "metadata": {
        "id": "_jrgSM0eHEaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f = w*x\n",
        "# f = 2*x\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "# loss\n",
        "def loss(y, y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # update weights\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "\n",
        "  # zero gradients\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epoch % 10  == 0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwvMANRXiahT",
        "outputId": "87898cdb-4ab8-4455-e94c-20bce6b53e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Training Pipeline Model/Loss/Optimization\n",
        "\n",
        "1) Design model (inout, output size, forward pass)\n",
        "\n",
        "2) Construct loss and optimizer\n",
        "\n",
        "3) Training loop\n",
        "\n",
        " - forward pass : compute prediction\n",
        " - backward pass : gradients\n",
        " - update weights"
      ],
      "metadata": {
        "id": "58vbSsvKI4ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f = w*x\n",
        "# f = 2*x\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# MSELoss is a callable function that takes y_true and y_pred as parameters\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "# We will optimize the parameter w\n",
        "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  # The loss is still the same because it's a callable function\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # We don't need to update manually our weights anymore\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10  == 0:\n",
        "    print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ctp10MuJFbM",
        "outputId": "dbc83e2e-3835-4f5f-e4bc-7489eae3111d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use implemented torch model"
      ],
      "metadata": {
        "id": "2ErKYNvAMUvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f = w*x\n",
        "# f = 2*x\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "# Get the shape\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# Construct a model\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# Linear is a callable function that takes X as a parameter and returns the rsult of forward pass\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# MSELoss is a callable function\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "# We don't have explicit weights now. Instead, we have the model's parameters\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # The loss is still the same because it's a callable function\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # We don't need to update manually our weights anymore\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10  == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0]:.3f}, b = {b[0]:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxHgl0iiMXU2",
        "outputId": "6750244e-506d-4529-dc42-fcae287a6dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 3.123\n",
            "epoch 1: w = 0.654, b = 0.865, loss = 12.16952896\n",
            "epoch 11: w = 1.457, b = 1.100, loss = 0.53136796\n",
            "epoch 21: w = 1.596, b = 1.109, loss = 0.21765824\n",
            "epoch 31: w = 1.627, b = 1.083, loss = 0.19767314\n",
            "epoch 41: w = 1.642, b = 1.052, loss = 0.18597826\n",
            "epoch 51: w = 1.653, b = 1.021, loss = 0.17514855\n",
            "epoch 61: w = 1.663, b = 0.991, loss = 0.16495383\n",
            "epoch 71: w = 1.673, b = 0.962, loss = 0.15535264\n",
            "epoch 81: w = 1.683, b = 0.933, loss = 0.14631025\n",
            "epoch 91: w = 1.692, b = 0.906, loss = 0.13779423\n",
            "Prediction after training: f(5) = 9.382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Custommized Model Class"
      ],
      "metadata": {
        "id": "bfPzj5yEPwK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# f = w*x\n",
        "# f = 2*x\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "# Get the shape\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# Construct a model\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# Linear is a callable function that takes X as a parameter and returns the rsult of forward pass\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# MSELoss is a callable function\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "# We don't have explicit weights now. Instead, we have the model's parameters\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  # prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  # The loss is still the same because it's a callable function\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  # gradients = backward pass\n",
        "  l.backward() # dl/dw\n",
        "\n",
        "  # We don't need to update manually our weights anymore\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10  == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0]:.3f}, b = {b[0]:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K5zPOL_P0rD",
        "outputId": "327f8bf3-8d59-457e-b944-b2aa97570022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 2.637\n",
            "epoch 1: w = 0.570, b = 0.875, loss = 14.07674789\n",
            "epoch 11: w = 1.434, b = 1.128, loss = 0.59320748\n",
            "epoch 21: w = 1.583, b = 1.140, loss = 0.23102668\n",
            "epoch 31: w = 1.617, b = 1.114, loss = 0.20910281\n",
            "epoch 41: w = 1.631, b = 1.082, loss = 0.19671252\n",
            "epoch 51: w = 1.643, b = 1.050, loss = 0.18525711\n",
            "epoch 61: w = 1.653, b = 1.019, loss = 0.17447419\n",
            "epoch 71: w = 1.664, b = 0.989, loss = 0.16431874\n",
            "epoch 81: w = 1.674, b = 0.960, loss = 0.15475452\n",
            "epoch 91: w = 1.683, b = 0.931, loss = 0.14574708\n",
            "Prediction after training: f(5) = 9.365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Linear Regression with Pytorch"
      ],
      "metadata": {
        "id": "akHHR1clRMUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise = 20, random_state=1)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  # forward pass and loss\n",
        "  y_predicted = model(X)\n",
        "  loss = criterion(y_predicted, y)\n",
        "\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# plot\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "QfyI7_mvRXIi",
        "outputId": "b337c867-5534-4e16-ad2b-65ad407f5212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 4470.6792\n",
            "epoch: 20, loss = 3335.6360\n",
            "epoch: 30, loss = 2513.7605\n",
            "epoch: 40, loss = 1918.0453\n",
            "epoch: 50, loss = 1485.8521\n",
            "epoch: 60, loss = 1172.0232\n",
            "epoch: 70, loss = 943.9609\n",
            "epoch: 80, loss = 778.1037\n",
            "epoch: 90, loss = 657.4037\n",
            "epoch: 100, loss = 569.5118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x79cbd4bc16c0>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Logistic Regression with pytorch"
      ],
      "metadata": {
        "id": "23yD6ESAU5xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) model : f = sig(xw+b)\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "# 2) loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  # forward pass and loss\n",
        "  y_predicted = model(X_train)\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  # updates\n",
        "  optimizer.step()\n",
        "\n",
        "  # zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Model evaluation\n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()\n",
        "  acc = y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
        "  print(f'accuracy = {acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "injHt0PhU9vD",
        "outputId": "2d6691de-ac64-4e0b-cd7e-677c00776635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.5608\n",
            "epoch: 20, loss = 0.4699\n",
            "epoch: 30, loss = 0.4101\n",
            "epoch: 40, loss = 0.3678\n",
            "epoch: 50, loss = 0.3362\n",
            "epoch: 60, loss = 0.3114\n",
            "epoch: 70, loss = 0.2913\n",
            "epoch: 80, loss = 0.2747\n",
            "epoch: 90, loss = 0.2605\n",
            "epoch: 100, loss = 0.2483\n",
            "accuracy = 0.8860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Dataset & DataLoader\n",
        "epoch = 1 forward and backward pass of ALL training samples\n",
        "\n",
        "batch_size = number of training samples in one forward & backward pass\n",
        "\n",
        "number of iterations = number of passes, each pass using [batch size] numberof samples\n",
        "\n",
        "e.g. 100 samples, batch_size = 20 ==> 100/20 = 5 iteration for each 1 epoch"
      ],
      "metadata": {
        "id": "oCUWMMdaZvTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WineDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # data loading\n",
        "    xy = np.loadtxt('wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:, 1:])\n",
        "    self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # dataset[0]\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "# training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (input, labels) in enumerate(dataloader):\n",
        "    # forward backward, update\n",
        "    if (i+1)%5 == 0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {input.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvSobkcGZyT_",
        "outputId": "a43e8ea8-90c4-4b15-c824-c64b14b656bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 45\n",
            "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
            "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Dataset Transforms"
      ],
      "metadata": {
        "id": "iYiM-EmUja-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WineDataset(Dataset):\n",
        "  def __init__(self, transform=None):\n",
        "    # data loading\n",
        "    xy = np.loadtxt('wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.x = xy[:, 1:]\n",
        "    self.y = xy[:, [0]] # n_samples, 1\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sample = self.x[index], self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "# callable object\n",
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    inputs, target = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, target\n",
        "\n",
        "\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features)\n",
        "print(type(features), type(labels))\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4 )])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features)\n",
        "print(type(features), type(labels))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLTp7CnJjfFS",
        "outputId": "cf1b3cd5-6deb-4b18-83d3-a7b5351e6c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
            "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
            "        4.2600e+03])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Softmax & Crossentropy\n",
        "```\n",
        "Softmax ==> nn.CrossEntropyLoss()\n",
        "binary classification ==> nn.BCELoss()\n",
        "```"
      ],
      "metadata": {
        "id": "eHjsxp69mK_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "Y = torch.tensor([2])\n",
        "# nsamples x nclasses = 1x3\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(l1.item())\n",
        "print(l2.item())\n",
        "\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(predictions1)\n",
        "print(predictions2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5WqoRREpDai",
        "outputId": "2b28ced5-3ba1-4203-e80f-9dabbb0385a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3170299530029297\n",
            "2.040616273880005\n",
            "tensor([0])\n",
            "tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-class Model\n",
        "When we use Crossentropy loss, we don't use softmax layer since it's corporated inside."
      ],
      "metadata": {
        "id": "fTevUtrW3LgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet2(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet2, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "\n",
        "    # no softmax at the end\n",
        "    return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss() # (applies softmax)"
      ],
      "metadata": {
        "id": "8qw393gX07in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Class Model"
      ],
      "metadata": {
        "id": "PKUbsXBk3RFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet1(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet1, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "\n",
        "    # sigmoid at the end\n",
        "    y_pred = torch.sigmoid(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "epGDCgyS3TGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Activation Functions\n",
        "\n",
        "1. **Step function**\n",
        "2. **Sigmoid**\n",
        "3. **TanH**\n",
        "4. **ReLU**\n",
        "5. **Leaky ReLU** : Improved version of ReLU. Tries to solve the vanishing gradient problem\n",
        "6. **Softmax**\n",
        "\n",
        "We have two ways to use them in Pytorch."
      ],
      "metadata": {
        "id": "dyVz-I_h5ygr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 01 :\n",
        "It corresponds to what we have seen earlier. We first define all the layers in the init method, then we call them  inside the forward method. In this case, we consider them as separated layer."
      ],
      "metadata": {
        "id": "8EHq6SAM8vYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "\n",
        "    # sigmoid at the end\n",
        "    out = torch.sigmoid(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "rLAB3g-K5-4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option 02 :\n",
        "We can use them directly in the forward method. In this case, the activation functions are incorporated in the same nodes of the same layer. They are directly available in `torch` API. Sometimes they are available in `torch.nn.functional`"
      ],
      "metadata": {
        "id": "DAwWUodu8-VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.linear2 = nn.Linear(hidden_size,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.relu(self.linear1(x))\n",
        "    out = torch.sigmoid(self.linear2(out))\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "r32drYij9Uhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Feed-Forward Neural Net\n",
        "\n",
        "1. MNIST\n",
        "2. DataLoader\n",
        "3. Multilayer Neural Net\n",
        "4. Loss & Optimizer\n",
        "5. Training Loop (batch training)\n",
        "6. Model evaluation\n",
        "7. GPU support"
      ],
      "metadata": {
        "id": "dettCkak-ah-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyper parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "examples = iter(train_loader)\n",
        "samples, labels = next(examples)\n",
        "print(samples.shape, labels.shape)\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.imshow(samples[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)\n",
        "\n",
        "#loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# training loop\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # 100, 1, 28, 28\n",
        "    # 100 784\n",
        "    # push the tensor to the GPU is available\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images).to(device)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "\n",
        "# test\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    # value, index\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_Tl3c_l_-yez",
        "outputId": "f1d288a8-fa56-4a9d-e046-a8851c99b19e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 9912422/9912422 [00:00<00:00, 225309636.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 28881/28881 [00:00<00:00, 114494984.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1648877/1648877 [00:00<00:00, 123657048.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 4542/4542 [00:00<00:00, 21722381.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/2, step 100/600, loss = 0.6751\n",
            "epoch 1/2, step 200/600, loss = 0.3019\n",
            "epoch 1/2, step 300/600, loss = 0.3147\n",
            "epoch 1/2, step 400/600, loss = 0.3555\n",
            "epoch 1/2, step 500/600, loss = 0.2907\n",
            "epoch 1/2, step 600/600, loss = 0.2604\n",
            "epoch 2/2, step 100/600, loss = 0.1908\n",
            "epoch 2/2, step 200/600, loss = 0.1995\n",
            "epoch 2/2, step 300/600, loss = 0.2124\n",
            "epoch 2/2, step 400/600, loss = 0.1480\n",
            "epoch 2/2, step 500/600, loss = 0.1688\n",
            "epoch 2/2, step 600/600, loss = 0.1563\n",
            "accuracy = 95.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. CNN with pytorch"
      ],
      "metadata": {
        "id": "z8ndgbXAOy6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 4\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1]\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship','truck')\n",
        "\n",
        "# implement conv net\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2= nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "model = ConvNet()\n",
        "\n",
        "#loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# training loop\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "    # input_layer : 3 input channels, 6 output channels, 5 kernel size\n",
        "    # push the tensor to the GPU is available\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 2000 == 0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# test\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    # max returns (value, index)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    n_samples += labels.size(0)\n",
        "    n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      label = labels[i]\n",
        "      pred = predicted[i]\n",
        "      if(label == pred):\n",
        "        n_class_correct[label] += 1\n",
        "      n_class_samples[label] += 1\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'Accuracy of the network = {acc} %')\n",
        "\n",
        "  for i in range(10):\n",
        "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "    print(f'Accuracy of {classes[i]}: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXNzy2ZqPXVa",
        "outputId": "1f140d3d-295a-4367-e911-26caae3ec3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170498071/170498071 [00:01<00:00, 103564424.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "epoch 1/4, step 2000/12500, loss = 2.3143\n",
            "epoch 1/4, step 4000/12500, loss = 2.2867\n",
            "epoch 1/4, step 6000/12500, loss = 2.2951\n",
            "epoch 1/4, step 8000/12500, loss = 2.2886\n",
            "epoch 1/4, step 10000/12500, loss = 2.2987\n",
            "epoch 1/4, step 12000/12500, loss = 2.2615\n",
            "epoch 2/4, step 2000/12500, loss = 2.4778\n",
            "epoch 2/4, step 4000/12500, loss = 2.0207\n",
            "epoch 2/4, step 6000/12500, loss = 2.4254\n",
            "epoch 2/4, step 8000/12500, loss = 1.7778\n",
            "epoch 2/4, step 10000/12500, loss = 1.7282\n",
            "epoch 2/4, step 12000/12500, loss = 2.1344\n",
            "epoch 3/4, step 2000/12500, loss = 1.4435\n",
            "epoch 3/4, step 4000/12500, loss = 1.6730\n",
            "epoch 3/4, step 6000/12500, loss = 2.5885\n",
            "epoch 3/4, step 8000/12500, loss = 1.2581\n",
            "epoch 3/4, step 10000/12500, loss = 1.1053\n",
            "epoch 3/4, step 12000/12500, loss = 1.7308\n",
            "epoch 4/4, step 2000/12500, loss = 1.1944\n",
            "epoch 4/4, step 4000/12500, loss = 1.0707\n",
            "epoch 4/4, step 6000/12500, loss = 1.4289\n",
            "epoch 4/4, step 8000/12500, loss = 1.0080\n",
            "epoch 4/4, step 10000/12500, loss = 1.4573\n",
            "epoch 4/4, step 12000/12500, loss = 0.9570\n",
            "Finished Training\n",
            "Accuracy of the network = 46.07 %\n",
            "Accuracy of plane: 47.0 %\n",
            "Accuracy of car: 63.4 %\n",
            "Accuracy of bird: 45.1 %\n",
            "Accuracy of cat: 32.3 %\n",
            "Accuracy of deer: 22.7 %\n",
            "Accuracy of dog: 24.7 %\n",
            "Accuracy of frog: 61.6 %\n",
            "Accuracy of horse: 51.8 %\n",
            "Accuracy of ship: 60.9 %\n",
            "Accuracy of truck: 51.2 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Transfer Learning\n",
        "\n",
        "### Scheduler\n",
        "```python\n",
        "# Every 7 epochs, our learning rate is multiplied by gamma\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "...\n",
        "for epoch in range(num_epochs):\n",
        "  for i in range(iterations):\n",
        "    ...\n",
        "    optimizer.step()\n",
        "    ...\n",
        "  step_lr_schedular.step()\n",
        "```\n",
        "\n",
        "### Transfer Learning\n",
        "```python\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# View model architecture\n",
        "summary(model, input_shape)\n",
        "\n",
        "# Access a specific layer\n",
        "model.layer_name\n",
        "\n",
        "# Access the parameters of the model\n",
        "model.parameters()\n",
        "\n",
        "# Access the parameters of the layer\n",
        "model.layer_name.parameters()\n",
        "\n",
        "# Freez the layer\n",
        "for param in model.layer_name.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Freez the parameters of the model\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "```\n",
        "\n",
        "The command `model.layer.parameters()` returns two tensors. One represents the *weights*, the other one represents the *biases*"
      ],
      "metadata": {
        "id": "9dhGPNqIdUQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2= nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "model = ConvNet()\n",
        "model.fc1.requires_grad_ = False\n",
        "for param in model.fc1.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "ZIPLu6pMvOV8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Tensorboard"
      ],
      "metadata": {
        "id": "pxEWJqYT48D7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vLXC0Ns4_cJ",
        "outputId": "023cad14-7858-456a-fda1-60eeb0d45c37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.57.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.41.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TENSORBOARD\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/mnist1')\n",
        "###################################################\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "#plt.show()\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "img_grid = torchvision.utils.make_grid(example_data)\n",
        "writer.add_image('mnist_images', img_grid)\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_graph(model, example_data.reshape(-1, 28*28).to(device))\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Train the model\n",
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "            ############## TENSORBOARD ########################\n",
        "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
        "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
        "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
        "            running_correct = 0\n",
        "            running_loss = 0.0\n",
        "            ###################################################\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "class_labels = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        values, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
        "\n",
        "        class_preds.append(class_probs_batch)\n",
        "        class_labels.append(labels)\n",
        "\n",
        "    # 10000, 10, and 10000, 1\n",
        "    # stack concatenates tensors along a new dimension\n",
        "    # cat concatenates tensors in the given dimension\n",
        "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
        "    class_labels = torch.cat(class_labels)\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "    ############## TENSORBOARD ########################\n",
        "    classes = range(10)\n",
        "    for i in classes:\n",
        "        labels_i = class_labels == i\n",
        "        preds_i = class_preds[:, i]\n",
        "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "        writer.close()\n",
        "    ###################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "69yRhqlNJlxK",
        "outputId": "972e6e6a-10e7-4af3-ad78-5005a16be06f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/938], Loss: 0.2461\n",
            "Epoch [1/1], Step [200/938], Loss: 0.1468\n",
            "Epoch [1/1], Step [300/938], Loss: 0.2078\n",
            "Epoch [1/1], Step [400/938], Loss: 0.2254\n",
            "Epoch [1/1], Step [500/938], Loss: 0.2102\n",
            "Epoch [1/1], Step [600/938], Loss: 0.1792\n",
            "Epoch [1/1], Step [700/938], Loss: 0.1813\n",
            "Epoch [1/1], Step [800/938], Loss: 0.3528\n",
            "Epoch [1/1], Step [900/938], Loss: 0.1033\n",
            "Accuracy of the network on the 10000 test images: 96.14 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/mnist1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "rWSyoJnh6RWS",
        "outputId": "8ebc6963-ded4-4e56-a449-f18eff956237"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "2023-08-27 19:14:29.295595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
              "\n",
              "NOTE: Using experimental fast data loading logic. To disable, pass\n",
              "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
              "    https://github.com/tensorflow/tensorboard/issues/4784\n",
              "\n",
              "Traceback (most recent call last):\n",
              "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
              "    sys.exit(run_main())\n",
              "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/main.py\", line 46, in run_main\n",
              "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
              "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
              "    _run_main(main, args)\n",
              "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
              "    sys.exit(main(argv))\n",
              "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/program.py\", line 276, in main\n",
              "    return runner(self.flags) or 0\n",
              "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/program.py\", line 292, in _run_serve_subcommand\n",
              "    server = self._make_server()\n",
              "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/program.py\", line 467, in _make_server\n",
              "    app = application.TensorBoardWSGIApp(\n",
              "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/backend/application.py\", line 139, in TensorBoardWSGIApp\n",
              "    return TensorBoardWSGI(\n",
              "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/backend/application.py\", line 252, in __init__\n",
              "    raise ValueError(\n",
              "ValueError: Duplicate plugins for name projector"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Saving and Loading Models\n",
        "**Option 01 :**\n",
        "```python\n",
        "#### COMPLETE MODEL ####\n",
        "torch.save(arg, PATH)\n",
        "\n",
        "# model class must be defined somwhere\n",
        "model = torch.load(PATH)\n",
        "model.eval()\n",
        "```\n",
        "\n",
        "**Option 02 :**\n",
        "```python\n",
        "#### STATE DICT ####\n",
        "# We saved the whole parameters of the model (dictionnary)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "# model must be created again with parameters\n",
        "# 1. First we create model object\n",
        "# 2. We load the dictionnary of parameters\n",
        "# 3. Set our model to evaluation mode\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()\n",
        "```\n",
        "\n",
        "The problem with the first option, is that the model should be in the same structure with which it's saved, so as to be correctely loaded.\n",
        "\n",
        "The recommended way to save our model is the second option."
      ],
      "metadata": {
        "id": "EI1AMg2ybLMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTION 01\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "print(optimizer.state_dict())\n",
        "\n",
        "# create a checkpoint\n",
        "checkpoint = {\n",
        "    \"epoch\" : 90,\n",
        "    \"model_state\" : model.state_dict(),\n",
        "    \"optim_state\" : optimizer.state_dict()\n",
        "}\n",
        "\n",
        "# in pytorch we can save any dictionnary. We use this advantage to create a checkpoints\n",
        "torch.save(checkpoint, \"checkpoint.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WNiNmV06WGs",
        "outputId": "c3f14f00-9253-4185-ce95-333b4f7c25aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_checkpoint = torch.load(\"checkpoint.pth\")"
      ],
      "metadata": {
        "id": "aD1108tCejWD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loaded_checkpoint)\n",
        "model = Model(n_input_features=6)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "epoch = loaded_checkpoint[\"epoch\"]\n",
        "model.load_state_dict(loaded_checkpoint[\"model_state\"])\n",
        "optimizer.load_state_dict(loaded_checkpoint[\"optim_state\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1-0e4_OFxu0",
        "outputId": "4a8f561c-f2b8-4ff0-9f0c-50096935291c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 90, 'model_state': OrderedDict([('linear.weight', tensor([[-0.3100, -0.3003, -0.3130,  0.2657, -0.0290,  0.0737]])), ('linear.bias', tensor([-0.3047]))]), 'optim_state': {'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and Load on a specific device\n",
        "\n",
        "```python\n",
        "# Save on GPU, Load on CPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=device))\n",
        "```\n",
        "\n",
        "\n",
        "```python\n",
        "# Save on GPU, Load on GPU\n",
        "device = torch.device(\"cuda\")\n",
        "model.to(device)\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.to(device)\n",
        "```\n",
        "\n",
        "```python\n",
        "# Save on CPU, Load on GPU\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "model = Model(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
        "model.to(device)\n",
        "```"
      ],
      "metadata": {
        "id": "Zx12u6vFHHg4"
      }
    }
  ]
}